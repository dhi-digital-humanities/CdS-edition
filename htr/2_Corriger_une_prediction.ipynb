{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corriger une prédiction HTR\n",
    "===\n",
    "<br>\n",
    "D'après la démarche expliquée dans la documentation du projet DAHN, on procède selon les étapes suivantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On privilégie le format XML-Page pour exporter et réimporter les prédictions HTR dans le logiciel de transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On place les prédictions HTR dans le dossier : ./xmlPage-aCorriger/\n"
     ]
    }
   ],
   "source": [
    "from py.constantes import XMLaCORRIGER, XMLCORRIGEES\n",
    "print(f\"\"\"On place les prédictions HTR dans le dossier : {XMLaCORRIGER}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter le script **spellcheck_texts_PAGEXML.py**, qui analyse chaque mot des prédictions HTR et génère pour chaque fichier XML à corriger un dictionnaire au format Json contenant des propositions de corrections : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier ./xmlPage-aCorriger/CdS02_Konv002-02_0175.xml est en cours de lecture.\n",
      "/home/sbiay/dhi/venv/lib/python3.8/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"py/spellcheck_texts_PAGEXML.py\", line 131, in <module>\n",
      "    spellcheck_texts_page_XML()\n",
      "  File \"py/spellcheck_texts_PAGEXML.py\", line 100, in spellcheck_texts_page_XML\n",
      "    if mot not in get_lemmes():\n",
      "  File \"py/spellcheck_texts_PAGEXML.py\", line 23, in get_lemmes\n",
      "    xml = etree.parse(f)\n",
      "  File \"src/lxml/etree.pyx\", line 3521, in lxml.etree.parse\n",
      "  File \"src/lxml/parser.pxi\", line 1880, in lxml.etree._parseDocument\n",
      "  File \"src/lxml/parser.pxi\", line 1900, in lxml.etree._parseFilelikeDocument\n",
      "  File \"src/lxml/parser.pxi\", line 1795, in lxml.etree._parseDocFromFilelike\n",
      "  File \"src/lxml/parser.pxi\", line 1201, in lxml.etree._BaseParser._parseDocFromFilelike\n",
      "  File \"src/lxml/parser.pxi\", line 615, in lxml.etree._ParserContext._handleParseResultDoc\n",
      "  File \"src/lxml/parser.pxi\", line 721, in lxml.etree._handleParseResult\n",
      "  File \"src/lxml/etree.pyx\", line 318, in lxml.etree._ExceptionContext._raise_if_stored\n",
      "  File \"src/lxml/parser.pxi\", line 370, in lxml.etree._FileReaderContext.copyToBuffer\n",
      "  File \"/usr/lib/python3.8/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "!python3 py/spellcheck_texts_PAGEXML.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corriger à la main les entrées du dictionnaire de chacun des fichiers générés dans le dossier [dictPages/](py/dictPages/).\n",
    "\n",
    "**Attention** : il faut bien veiller à…\n",
    "- Ne pas transformer de mots qui seraient justes dans un autre contexte (comme le mot **\"tout\"** dans l'exemple suivant, qui ne doit pas être corrigé en \"août\" bien que le contexte s'y prête, au risque de modifier des \"tout\" pertinents dans leur propre contexte)\n",
    "\n",
    "- Éliminer les propositions de lemmes erronées, en modifiant le lemme comme \"null\" (**\"Paris\"** dans l'exemple suivant)\n",
    "\n",
    "Il n'est pas nécessaire de transformer les mots justes dont le lemme est indiqué comme \"null\", car ils seront intégrés au réservoir des mots connus dès leurs prochaine rencontre (ici l'exemple de **\"homme\"**).\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"tout\": {\n",
    "      \"lem\": null,\n",
    "      \"ctxt\": \"Dyck, ce 3 TOUT 1818\"\n",
    "   },\n",
    "    \"Paris\": {\n",
    "      \"lem\": \"pris\",\n",
    "      \"ctxt\": \"c est qu il retournera à PARIS dans le mois de Mre comme\"\n",
    "   },\n",
    "    \"homme\": {\n",
    "      \"lem\": null,\n",
    "      \"ctxt\": \"ce brane HOMME se rétablisse ranais  tout ce qu on peut espeden-\"\n",
    "   },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois cette tâche accomplie, on applique le script [dictCDSmanip.py](./py/dictCDSmanip.py). Voyons dans un premier temps son rôle et les options qu'il propose :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dictCDSmanip.py [OPTIONS]\r\n",
      "\r\n",
      "  Ce script prend comme paramètres une source consistant en un fichier Json\r\n",
      "  d'entrée contenu dans le dossier dictPages le compare au contenu de\r\n",
      "  dictCDS.json, intègre les entrées nouvelles et retourne des messages\r\n",
      "  d'alertes pour les entrées générant un conflit d'intégration. :param\r\n",
      "  fichierdictpages: fichier Json issu de la correction automatisée d'une\r\n",
      "  page de transcription :type fichierdictpages: Json :returns: None\r\n",
      "\r\n",
      "Options:\r\n",
      "  -f, --file TEXT  Nom de fichier contenu dans le dossier ./py/dictPages/\r\n",
      "  -A, --all        Prend tous les fichiers du dossier ./py/dictPages/\r\n",
      "  --help           Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 py/dictCDSmanip.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"py/dictCDSmanip.py\", line 80, in <module>\r\n",
      "    dictCDSintegration()\r\n",
      "  File \"/home/sbiay/dhi/venv/lib/python3.8/site-packages/click/core.py\", line 764, in __call__\r\n",
      "    return self.main(*args, **kwargs)\r\n",
      "  File \"/home/sbiay/dhi/venv/lib/python3.8/site-packages/click/core.py\", line 717, in main\r\n",
      "    rv = self.invoke(ctx)\r\n",
      "  File \"/home/sbiay/dhi/venv/lib/python3.8/site-packages/click/core.py\", line 956, in invoke\r\n",
      "    return ctx.invoke(self.callback, **ctx.params)\r\n",
      "  File \"/home/sbiay/dhi/venv/lib/python3.8/site-packages/click/core.py\", line 555, in invoke\r\n",
      "    return callback(*args, **kwargs)\r\n",
      "  File \"py/dictCDSmanip.py\", line 70, in dictCDSintegration\r\n",
      "    with open(f\"./py/dictPages/{file}\") as f:\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './py/dictPages/None'\r\n"
     ]
    }
   ],
   "source": [
    "# Ajouter l'option qui convient et relancer le script\n",
    "!python3 py/dictCDSmanip.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le dictionnaire de correction aux fichiers XML grâce au script [text_correction_XML.py](./py/text_correction_XML.py) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier CdS02_Konv002-02_0067.xml a été corrigé avec succès\r\n",
      "Le dictionnaire dictCDS.json est désormais à jour.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 py/text_correction_XML.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On finalise le processus de correction avec les étapes suivantes :\n",
    "1. Réimporter les fichiers corrigés dans eScriptorium ;\n",
    "2. Finaliser manuellement la correction des transcriptions ;\n",
    "3. Télécharger la verité de terrain pour la sauvegarder au format XML-Alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On place les vérités de terrain dans le dossier : ./xmlPage-corrigees/\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"On place les vérités de terrain dans le dossier : {XMLCORRIGEES}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
