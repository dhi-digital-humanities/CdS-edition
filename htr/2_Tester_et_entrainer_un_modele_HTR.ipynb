{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99024783",
   "metadata": {},
   "source": [
    "Tester et entraîner un modèle de reconnaissance d'écriture\n",
    "===\n",
    "<br>\n",
    "\n",
    "Les dossiers qui constituent l'archive de la correspondance de Constance de Salm réunissent des documents écrits par plusieurs scribes. La différence des écritures représente une difficulté certaine pour la reconnaissance automatique.\n",
    "\n",
    "Ce *notebook* explique comment procéder à la reconnaissance automatique de l'écriture dans ce contexte particulier impliquant de multiples écritures.\n",
    "\n",
    "# Classer les images par mains\n",
    "\n",
    "Inventorier toutes les mains attestées dans une source n'est pas toujours aisé.\n",
    "\n",
    "L'objectif reste avant tout de repérer les mains principales : celles attestées sur le plus grand nombre de pages. Une main qui ne serait attestée que sur une dizaine de pages ne mériterait pas d'être classée, car entraîner un modèle de reconnaissance d'écriture pour un petit nombre de pages est une perte de temps.\n",
    "\n",
    "Une fois les mains principales repérées, on renseigne le fichier [mains.csv](./sources/mains.csv) qui jouera un rôle  dans l'évaluation des modèles et leur entraînement.\n",
    "\n",
    "# Créer un échantillon-test de chaque écriture\n",
    "\n",
    "Afin de pouvoir tester un ou plusieurs modèles, il est nécessaire de constituer une vérité de terrain de 2-3 doubles pages (selon la densité d'écriture qu'elles contiennent).\n",
    "\n",
    "## Critères de sélection\n",
    "\n",
    "On crée dans le dossier de chaque main un dossier **test** contenant des spécimens d'écriture selon les critères suivants :\n",
    "- Reproductions de bonne qualité (sans problème de transparence)\n",
    "- Pages choisies de manière discontinue (l'écriture d'une même main peut en effet varier et il est utile de prendre en compte cette variété pour le test)\n",
    "\n",
    "Si certaines mains ne sont attestées qu'en compagnie d'autres écritures, on veillera à limiter le test de reconnaissance d'écriture aux seuls lignes de la main à tester (en supprimant après segmentation les lignes non pertinentes afin que la reconnaissance de l'écriture ne les traite pas).\n",
    "\n",
    "## Organisation des fichiers\n",
    "\n",
    "Voici un modèle d'arborescence pour le rangement et le nommage des fichiers et dossiers :\n",
    "```txt\n",
    "sources/\n",
    "├── mainCdS02_Konv002_01/\n",
    "│   ├── test/\n",
    "│   │   ├── CdS02_Konv002-02_0065.jpg\n",
    "│   │   ├── CdS02_Konv002-02_0073.jpg\n",
    "│   ├── train/\n",
    "├── mainCdS02_Konv019_01/\n",
    "│   ├── test/\n",
    "│   │   ├── CdS02_Konv019_0002.jpg\n",
    "│   │   ├── CdS02_Konv019_0003.jpg\n",
    "│   └── train/\n",
    "├── mains.csv\n",
    "└── modeles/\n",
    "```\n",
    "\n",
    "## Critères de transcription\n",
    "\n",
    "On suit de manière rigoureuse les préconisations pour la transcription énoncées dans la [documentation analytique](https://github.com/sbiay/CdS-edition/blob/main/documentation/documentation.pdf) (cf. annexe Normes de transcription).\n",
    "\n",
    "\n",
    "# Tester des modèles HTR\n",
    "\n",
    "## Installer l'application Kraken\n",
    "\n",
    "On recommande pour tester un modèle d'utiliser l'application Kraken en ligne de commande, disponible pour Linux et Mac OSX (non pour Windows). Les instructions sont consultables [ici](https://github.com/mittagessen/kraken#installation).\n",
    "\n",
    "## Importer un modèle\n",
    "\n",
    "Les modèles extérieurs au projet que l'on a utilisés sont téléchargeables sur le [Gitlab du laboratoire Inria](https://gitlab.inria.fr/dh-projects/kraken-models/-/tree/master/transcription%20models) :\n",
    "- generic_lectaurep_26.mlmodel\n",
    "- cm_ft_mrs15_11.mlmodel\n",
    "\n",
    "## Initier un journal de tests\n",
    "\n",
    "Le script [journalReconn.py](./py/journalReconn.py) permet de pré-remplir un journal pour l'enregistrement des résultats des tests effectués sur les modèles. \n",
    "\n",
    "On lui donne comme argument un nom de modèle et il écrit dans le fichier Json [journal-rec.json](./sources/journal-rec.json), à la date et à l'heure courante et pour chaque main listée dans le fichier [mains.csv](./sources/mains.csv), les noms de ces mains et prépare le renseignement des valeurs de test.\n",
    "\n",
    "Conseils d'utilisation :\n",
    "- Paramètre MODELE : obligatoire ; reseigner un **nom de modèle** plutôt que son chemin relatif ou absolu\n",
    "- Option -v, --veriteterrain : le test initial se fait naturellement sans avoir entraîné le modèle sur les vérités de terrain\n",
    "- Option -i, --ignore : pour ignorer une main listée dans le fichier [mains.csv](./sources/mains.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6197a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 py/journalReconn.py MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829132d3",
   "metadata": {},
   "source": [
    "Le contenu écrit dans le fichier journal donne comme **accuracy** pour chaque main une valeur de 0. Cette valeur doit être saisie manuellement dans le fichier une fois effectué le test comme suit.\n",
    "\n",
    "\n",
    "## Effectuer un test\n",
    "\n",
    "Avec la commande suivante on effectue un test d'acuité pour un modèle sur une main particulière (on doit relever l'*Average accuracy*) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9340df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Torch version 1.11.0+cu102 has not been tested with coremltools. You may run into unexpected errors. Torch 1.10.2 is the most recent version that has been tested.\n",
      "Loading model ./sources/modeles-rec/cm_ft_mrs15_11.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Evaluating ./sources/modeles-rec/cm_ft_mrs15_11.mlmodel\u001b[0m\n",
      "\u001b[2KEvaluating \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m88/88\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:22\u001b[0m[0m \u001b[36m0:00:01\u001b[0m \u001b[33m0:00:22\u001b[0m\n",
      "\u001b[?25h=== report  ===\n",
      "\n",
      "4981\tCharacters\n",
      "186\tErrors\n",
      "96.27%\tAccuracy\n",
      "\n",
      "38\tInsertions\n",
      "25\tDeletions\n",
      "123\tSubstitutions\n",
      "\n",
      "Count\tMissed\t%Right\n",
      "3946\t127\t96.78%\tLatin\n",
      "1035\t34\t96.71%\tCommon\n",
      "\n",
      "Errors\tCorrect-Generated\n",
      "15\t{ é } - { e }\n",
      "9\t{ . } - {  }\n",
      "9\t{ a } - { u }\n",
      "7\t{ SPACE } - {  }\n",
      "6\t{  } - { e }\n",
      "5\t{ o } - { a }\n",
      "4\t{ n } - { u }\n",
      "4\t{ u } - { n }\n",
      "4\t{  } - { SPACE }\n",
      "3\t{ , } - {  }\n",
      "3\t{  } - { . }\n",
      "3\t{ r } - {  }\n",
      "3\t{ a } - { à }\n",
      "3\t{  } - { - }\n",
      "3\t{ SPACE } - { . }\n",
      "3\t{ a } - { o }\n",
      "3\t{ l } - { t }\n",
      "2\t{ è } - { i }\n",
      "2\t{ e } - { i }\n",
      "2\t{ x } - { 2 }\n",
      "2\t{ i } - { e }\n",
      "2\t{ l } - {  }\n",
      "2\t{ t } - { s }\n",
      "2\t{ S } - { s }\n",
      "2\t{ ç } - { c }\n",
      "2\t{ : } - {  }\n",
      "2\t{ V } - { v }\n",
      "2\t{ d } - {  }\n",
      "2\t{ r } - { t }\n",
      "2\t{ c } - { e }\n",
      "2\t{ t } - {  }\n",
      "2\t{ n } - { m }\n",
      "2\t{ q } - { g }\n",
      "2\t{ e } - { é }\n",
      "1\t{ , } - { SPACE }\n",
      "1\t{  } - { ; }\n",
      "1\t{ : } - { ; }\n",
      "1\t{ M } - { m }\n",
      "1\t{ m } - { M }\n",
      "1\t{ j } - { J }\n",
      "1\t{ l } - { L }\n",
      "1\t{ &#39; } - {  }\n",
      "1\t{ î } - { i }\n",
      "1\t{ t } - { x }\n",
      "1\t{ i } - { y }\n",
      "1\t{ P } - { R }\n",
      "1\t{ r } - { s }\n",
      "1\t{ s } - { t }\n",
      "1\t{ p } - { x }\n",
      "1\t{ - } - { SPACE }\n",
      "1\t{ é } - { c }\n",
      "1\t{  } - { J }\n",
      "1\t{  } - { t }\n",
      "1\t{ è } - { e }\n",
      "1\t{ m } - { p }\n",
      "1\t{ g } - { m }\n",
      "1\t{ a } - {  }\n",
      "1\t{ n } - {  }\n",
      "1\t{  } - { , }\n",
      "1\t{  } - { m }\n",
      "1\t{ t } - { r }\n",
      "1\t{ é } - { i }\n",
      "1\t{  } - { l }\n",
      "1\t{ u } - { i }\n",
      "1\t{ SPACE } - { - }\n",
      "1\t{ g } - { y }\n",
      "1\t{ p } - { s }\n",
      "1\t{ f } - { t }\n",
      "1\t{ d } - { c }\n",
      "1\t{ H } - { B }\n",
      "1\t{ h } - { z }\n",
      "1\t{ s } - { z }\n",
      "1\t{ a } - { r }\n",
      "1\t{ . } - { SPACE }\n",
      "1\t{  } - { : }\n",
      "1\t{ o } - { s }\n",
      "1\t{ d } - { r }\n",
      "1\t{ 8 } - { &amp; }\n",
      "1\t{ SPACE } - { c }\n",
      "1\t{ é } - {  }\n",
      "1\t{ c } - {  }\n",
      "1\t{ g } - { q }\n",
      "1\t{ r } - { u }\n",
      "1\t{ s } - { P }\n",
      "1\t{ a } - { n }\n",
      "1\t{ - } - {  }\n",
      "1\t{ 8 } - { 6 }\n",
      "1\t{ ê } - { i }\n",
      "1\t{ i } - {  }\n",
      "1\t{ s } - { S }\n",
      "1\t{  } - { s }\n",
      "1\t{ e } - { t }\n",
      "1\t{ e } - { a }\n",
      "1\t{ s } - { d }\n",
      "1\t{  } - { u }\n",
      "1\t{ u } - {  }\n",
      "1\t{ ỻ } - { f }\n",
      "1\t{ G } - { g }\n",
      "1\t{ n } - { v }\n",
      "\u001b[0m\n",
      "Average accuracy: 96.27%, (stddev: 0.00)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ketos test -m ../sources/modeles-rec/NOM-MODEL.mlmodel sources/NOM-MAIN/test/*xml -f alto\n",
    "!ketos test -m ./sources/modeles-rec/cm_ft_mrs15_11.mlmodel sources/mainCdS02_Konv019_02/test/*xml -f alto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e7253",
   "metadata": {},
   "source": [
    "Il convient de choisir le modèle présentant **les meilleurs résultats pour l'ensemble des écritures testées**. Si le meilleur modèle n'atteint pas 90% pour tout ou partie des mains, il convient de l'entraîner par l'apport de vérités de terrain pour chaque main n'atteignant pas ce score.\n",
    "\n",
    "# Entraîner un modèle\n",
    "\n",
    "On procède à la constitution d'une vérité de terrain pour chaque spécimen d'écriture. Il s'agit de transcrire l'**équivalent d'une dizaine de pages simples** : si les pages présentent des blancs importants ou d'autres écritures étrangères à l'entraînement (elles ne doivent pas être transcrites) on augmentera le nombre de pages pour parvenir grosso modo à ce volume de 10 pages simples.\n",
    "\n",
    "La transcription de ces pages se fait à la main, sans l'aide d'une première reconnaissance de l'écriture, car il est plus compliqué de corriger une mauvaise prédiction que de transcrire manuellement.\n",
    "\n",
    "On procède à la segmentation de la page (comme expliqué dans le notebook [suivant](./2_Realiser_une_prediction_HTR.ipynb)). On se contente d'une segmentation automatique, puis on transcrit les lignes manuellement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
